{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-_p4dk1PMH0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar Datos"
      ],
      "metadata": {
        "id": "on33hiiUPZlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/datos_limpios/cultivos_enriquecidos_espanol2.csv\")\n",
        "\n",
        "if len(df) != 1700:\n",
        "    raise ValueError(f\"El dataset debe tener exactamente 1,700 filas. Actualmente tiene {len(df)} filas.\")\n",
        "\n",
        "train_size = int(len(df) * 0.85)\n",
        "test_size = len(df) - train_size\n",
        "\n",
        "# Seleccionar datos de forma aleatoria para entrenamiento\n",
        "df_train = df.sample(n=train_size, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Usar el resto para prueba\n",
        "df_test = df.drop(df_train.index).reset_index(drop=True)\n",
        "\n",
        "# Validar que ambos conjuntos tienen datos\n",
        "if len(df_train) == 0 or len(df_test) == 0:\n",
        "    raise ValueError(\"Los conjuntos de entrenamiento o prueba están vacíos. Revisa el tamaño del dataset.\")\n",
        "\n",
        "# Separar características y etiquetas\n",
        "X_train = df_train.drop(columns=[\"label\"]).values\n",
        "y_train = df_train[\"label\"].values\n",
        "\n",
        "X_test = df_test.drop(columns=[\"label\"]).values\n",
        "y_test = df_test[\"label\"].values\n",
        "\n",
        "# Codificar las etiquetas\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "# Normalizar las características\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Aplicar el escalador\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(\"Datos de entrenamiento:\", X_train.shape)\n",
        "print(\"Datos de prueba:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmEFM8v8Pa_Q",
        "outputId": "85a5292a-b943-4790-85f2-d3a68461c7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de entrenamiento: (1445, 7)\n",
            "Datos de prueba: (255, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear un Dataset Personalizado"
      ],
      "metadata": {
        "id": "HJgC08KyPu3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CropDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# Crear datasets de entrenamiento y prueba\n",
        "train_dataset = CropDataset(X_train, y_train)\n",
        "test_dataset = CropDataset(X_test, y_test)\n",
        "\n",
        "# Crear dataloaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "4xaKaAhiP1bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir el Modelo"
      ],
      "metadata": {
        "id": "61SIo88dP5cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplifiedCropModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimplifiedCropModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(7, 64)\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimplifiedCropModel(num_classes=len(label_encoder.classes_))"
      ],
      "metadata": {
        "id": "BPHTCB5NP-2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del Modelo"
      ],
      "metadata": {
        "id": "ennHVTRoQGz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Entrenar\n",
        "num_epochs = 300\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Imprimir pérdida promedio por época\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IoKVxE5hSqJ",
        "outputId": "82f586cb-3747-45a8-e956-ae188ee58dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/300], Loss: 0.8009\n",
            "Epoch [20/300], Loss: 0.7066\n",
            "Epoch [30/300], Loss: 0.6599\n",
            "Epoch [40/300], Loss: 0.6527\n",
            "Epoch [50/300], Loss: 0.6390\n",
            "Epoch [60/300], Loss: 0.6267\n",
            "Epoch [70/300], Loss: 0.6137\n",
            "Epoch [80/300], Loss: 0.6185\n",
            "Epoch [90/300], Loss: 0.6056\n",
            "Epoch [100/300], Loss: 0.6027\n",
            "Epoch [110/300], Loss: 0.5917\n",
            "Epoch [120/300], Loss: 0.5891\n",
            "Epoch [130/300], Loss: 0.5919\n",
            "Epoch [140/300], Loss: 0.5807\n",
            "Epoch [150/300], Loss: 0.5720\n",
            "Epoch [160/300], Loss: 0.5674\n",
            "Epoch [170/300], Loss: 0.5640\n",
            "Epoch [180/300], Loss: 0.5682\n",
            "Epoch [190/300], Loss: 0.5598\n",
            "Epoch [200/300], Loss: 0.5642\n",
            "Epoch [210/300], Loss: 0.5531\n",
            "Epoch [220/300], Loss: 0.5540\n",
            "Epoch [230/300], Loss: 0.5517\n",
            "Epoch [240/300], Loss: 0.5423\n",
            "Epoch [250/300], Loss: 0.5372\n",
            "Epoch [260/300], Loss: 0.5291\n",
            "Epoch [270/300], Loss: 0.5322\n",
            "Epoch [280/300], Loss: 0.5261\n",
            "Epoch [290/300], Loss: 0.5251\n",
            "Epoch [300/300], Loss: 0.5244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación del Modelo"
      ],
      "metadata": {
        "id": "U-1gOnT0at6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy on the test set: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AboHnxTAavUQ",
        "outputId": "a3846b69-8d47-4bc8-b001-f2381e26f657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 54.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realizar una predicción de prueba"
      ],
      "metadata": {
        "id": "14jgN5bqbGd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = [[28,37,28,32.13409675,50.52559148,6.097869767,98.63333684]]\n",
        "sample = scaler.transform(sample)\n",
        "sample = torch.tensor(sample, dtype=torch.float32)\n",
        "\n",
        "model.eval()\n",
        "output = model(sample)\n",
        "_, predicted_label = torch.max(output, 1)\n",
        "print(\"Predicted Label:\", label_encoder.inverse_transform(predicted_label.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCde9nrmQ6ea",
        "outputId": "97a07c90-97c6-4125-fc54-de522927e54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: ['Mango']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AaICxJ0pQOUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"crop_classifier.pth\")"
      ],
      "metadata": {
        "id": "hbLSBebFQVnb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}